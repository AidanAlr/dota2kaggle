{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T18:02:18.492126Z",
     "start_time": "2025-06-05T18:02:16.784955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from typing import Dict, Any\n",
    "import logging\n",
    "from dataclasses import dataclass\n",
    "import warnings\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "from sklearn.model_selection import HalvingGridSearchCV # noqa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "warnings.filterwarnings('ignore')\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T18:02:19.036698Z",
     "start_time": "2025-06-05T18:02:18.492630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data = pd.read_csv('train_data.csv')\n",
    "test_features = pd.read_csv('test_data.csv')"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "player_numbers = ['1', '2', '3', '4', '5']\n",
    "stats = ['gold', 'xp', 'roshans_killed', 'firstblood_claimed', 'camps_stacked', 'creeps_stacked', 'lh', 'deaths']\n",
    "\n",
    "# Remove unwanted stats \n",
    "stats_with_player_lead = stats.copy()\n",
    "stats_with_player_lead.remove('roshans_killed')\n",
    "stats_with_player_lead.remove('firstblood_claimed')\n",
    "\n",
    "stats_with_team_lead = stats.copy()\n",
    "stats_with_team_lead.remove('firstblood_claimed')\n",
    "for df in [train_data, test_features]:\n",
    "    \n",
    "    # Custom Features\n",
    "    carry_multiplier = 1.10\n",
    "    \n",
    "    d1_gold_lead = df['d1_gold'] - df['r1_gold']\n",
    "    d2_gold_lead = df['d2_gold'] - df['r2_gold']\n",
    "    df['dire_carries_gold_lead'] = d1_gold_lead * carry_multiplier + d2_gold_lead\n",
    "    \n",
    "    d1_xp_lead = df['d1_xp'] - df['r1_xp']\n",
    "    d2_xp_lead = df['d2_xp'] - df['r2_xp']\n",
    "    df['dire_carries_xp_lead'] = d1_xp_lead * carry_multiplier + d2_xp_lead\n",
    "    \n",
    "    # Team Stats\n",
    "    for stat in stats_with_team_lead:\n",
    "        df[f'dire_team_{stat}'] = df[[f'd{number}_{stat}' for number in player_numbers]].sum(axis=1)\n",
    "        df[f'radiant_team_{stat}'] = df[[f'r{number}_{stat}' for number in player_numbers]].sum(axis=1)\n",
    "        df[f'dire_team_{stat}_lead'] = df[f'dire_team_{stat}'] - df[f'radiant_team_{stat}']\n",
    "\n",
    "    # Player Stat leads\n",
    "    for number in player_numbers:\n",
    "        for stat in stats_with_player_lead:\n",
    "            df[f'd{number}_{stat}_lead'] = df[f'd{number}_{stat}'] - df[f'r{number}_{stat}']"
   ],
   "metadata": {
    "id": "aOepAZeSU46b",
    "ExecuteTime": {
     "end_time": "2025-06-05T18:02:19.132454Z",
     "start_time": "2025-06-05T18:02:19.037703Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "# Remove unwanted columns\n",
    "columns_to_drop = []\n",
    "player_stats_to_drop = stats + ['x', 'y']\n",
    "player_stats_to_drop.remove('firstblood_claimed')  # Remove firstblood_claimed as it is not in test data\n",
    "columns_to_drop += ['lobby_type']\n",
    "for stat in player_stats_to_drop:\n",
    "    for team in ['r', 'd']:\n",
    "        columns_to_drop.extend([f'{team}{number}_{stat}' for number in player_numbers])\n",
    "\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_features.drop(columns=columns_to_drop, inplace=True)"
   ],
   "metadata": {
    "id": "c7JUluRGdoLI",
    "ExecuteTime": {
     "end_time": "2025-06-05T18:02:19.171189Z",
     "start_time": "2025-06-05T18:02:19.133460Z"
    }
   },
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": "train_data",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "3J78_5B3c-G8",
    "outputId": "bef91d2a-c408-4834-e554-7fa9a2973ce6",
    "ExecuteTime": {
     "end_time": "2025-06-05T18:02:19.200342Z",
     "start_time": "2025-06-05T18:02:19.172196Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       game_time  game_mode  objectives_len  chat_len  r1_hero_id  r1_kills  \\\n",
       "0            871         22               4         2         110         2   \n",
       "1           2549         22              17         0         114        16   \n",
       "2           1841         22               8         1         100         2   \n",
       "3           2211         22              11         3          32        14   \n",
       "4            458         22               1         0          68         3   \n",
       "...          ...        ...             ...       ...         ...       ...   \n",
       "29670       1664          3               8         0          17         1   \n",
       "29671       2898         22              26       108          89         4   \n",
       "29672       1246         23               6        10          51         9   \n",
       "29673       2620         22              15        10         114         9   \n",
       "29674       1111         22               5        12          63         0   \n",
       "\n",
       "       r1_assists  r1_denies  r1_health  r1_max_health  ...  \\\n",
       "0              11          3        497           1120  ...   \n",
       "1              12         24       2086           2600  ...   \n",
       "2              12          2       1009           1500  ...   \n",
       "3              11         21       1166           1940  ...   \n",
       "4               0         15        235            820  ...   \n",
       "...           ...        ...        ...            ...  ...   \n",
       "29670           1          8       1440           1440  ...   \n",
       "29671          17          5       1928           2600  ...   \n",
       "29672          15         16       4055           4055  ...   \n",
       "29673           5         10       3205           3205  ...   \n",
       "29674           3          3        839            860  ...   \n",
       "\n",
       "       d4_camps_stacked_lead  d4_creeps_stacked_lead  d4_lh_lead  \\\n",
       "0                          4                       8          23   \n",
       "1                         -1                      -3         152   \n",
       "2                          3                       5           7   \n",
       "3                          0                       0         -55   \n",
       "4                          0                       0           9   \n",
       "...                      ...                     ...         ...   \n",
       "29670                      1                       2         192   \n",
       "29671                      0                       0          21   \n",
       "29672                      0                       0          -7   \n",
       "29673                      2                       6         280   \n",
       "29674                      4                      13           3   \n",
       "\n",
       "       d4_deaths_lead  d5_gold_lead  d5_xp_lead  d5_camps_stacked_lead  \\\n",
       "0                   5         -3350       -4142                      0   \n",
       "1                  -1          2797        -253                      0   \n",
       "2                  -1         -2107       -1747                     -1   \n",
       "3                   8          1459        -818                     -1   \n",
       "4                   0          -166          24                      0   \n",
       "...               ...           ...         ...                    ...   \n",
       "29670               1          3605        2744                     -3   \n",
       "29671               1         -7952       -1388                      0   \n",
       "29672               0          3896        5710                      0   \n",
       "29673               0         -7072          -7                     -1   \n",
       "29674               2           929        -275                      4   \n",
       "\n",
       "       d5_creeps_stacked_lead  d5_lh_lead  d5_deaths_lead  \n",
       "0                           0         -77               5  \n",
       "1                           0          85               5  \n",
       "2                          -3        -133              -2  \n",
       "3                          -2          77               0  \n",
       "4                           0          -1               1  \n",
       "...                       ...         ...             ...  \n",
       "29670                     -10          19              -9  \n",
       "29671                       0         -76              -3  \n",
       "29672                       0          -7               0  \n",
       "29673                      -2        -185              -1  \n",
       "29674                      11          -2              -3  \n",
       "\n",
       "[29675 rows x 209 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_time</th>\n",
       "      <th>game_mode</th>\n",
       "      <th>objectives_len</th>\n",
       "      <th>chat_len</th>\n",
       "      <th>r1_hero_id</th>\n",
       "      <th>r1_kills</th>\n",
       "      <th>r1_assists</th>\n",
       "      <th>r1_denies</th>\n",
       "      <th>r1_health</th>\n",
       "      <th>r1_max_health</th>\n",
       "      <th>...</th>\n",
       "      <th>d4_camps_stacked_lead</th>\n",
       "      <th>d4_creeps_stacked_lead</th>\n",
       "      <th>d4_lh_lead</th>\n",
       "      <th>d4_deaths_lead</th>\n",
       "      <th>d5_gold_lead</th>\n",
       "      <th>d5_xp_lead</th>\n",
       "      <th>d5_camps_stacked_lead</th>\n",
       "      <th>d5_creeps_stacked_lead</th>\n",
       "      <th>d5_lh_lead</th>\n",
       "      <th>d5_deaths_lead</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>871</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>110</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>497</td>\n",
       "      <td>1120</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>-3350</td>\n",
       "      <td>-4142</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-77</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2549</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>2086</td>\n",
       "      <td>2600</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3</td>\n",
       "      <td>152</td>\n",
       "      <td>-1</td>\n",
       "      <td>2797</td>\n",
       "      <td>-253</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1841</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1009</td>\n",
       "      <td>1500</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2107</td>\n",
       "      <td>-1747</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3</td>\n",
       "      <td>-133</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2211</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>1166</td>\n",
       "      <td>1940</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-55</td>\n",
       "      <td>8</td>\n",
       "      <td>1459</td>\n",
       "      <td>-818</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>458</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>235</td>\n",
       "      <td>820</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>-166</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29670</th>\n",
       "      <td>1664</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1440</td>\n",
       "      <td>1440</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>192</td>\n",
       "      <td>1</td>\n",
       "      <td>3605</td>\n",
       "      <td>2744</td>\n",
       "      <td>-3</td>\n",
       "      <td>-10</td>\n",
       "      <td>19</td>\n",
       "      <td>-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29671</th>\n",
       "      <td>2898</td>\n",
       "      <td>22</td>\n",
       "      <td>26</td>\n",
       "      <td>108</td>\n",
       "      <td>89</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>1928</td>\n",
       "      <td>2600</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>-7952</td>\n",
       "      <td>-1388</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-76</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29672</th>\n",
       "      <td>1246</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>51</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>4055</td>\n",
       "      <td>4055</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-7</td>\n",
       "      <td>0</td>\n",
       "      <td>3896</td>\n",
       "      <td>5710</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29673</th>\n",
       "      <td>2620</td>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>114</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>3205</td>\n",
       "      <td>3205</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>280</td>\n",
       "      <td>0</td>\n",
       "      <td>-7072</td>\n",
       "      <td>-7</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-185</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29674</th>\n",
       "      <td>1111</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>839</td>\n",
       "      <td>860</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>929</td>\n",
       "      <td>-275</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>-2</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29675 rows × 209 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "X_train, X_val = train_test_split(train_data, test_size=0.2)\n",
    "\n",
    "y_train = X_train['radiant_win']\n",
    "X_train = X_train.drop(['radiant_win', 'ID'], axis=1)\n",
    "\n",
    "y_val = X_val['radiant_win']\n",
    "X_val = X_val.drop(['radiant_win', 'ID'], axis=1)\n",
    "\n",
    "X_test = test_features.drop('ID', axis=1)"
   ],
   "metadata": {
    "id": "dNni4MC9U5xm",
    "ExecuteTime": {
     "end_time": "2025-06-05T18:02:19.289042Z",
     "start_time": "2025-06-05T18:02:19.200848Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DH2vc07KDE7y",
    "ExecuteTime": {
     "end_time": "2025-06-05T18:02:20.308675Z",
     "start_time": "2025-06-05T18:02:19.290049Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_scaler_results(scaler_results_dict):\n",
    "    \"\"\"\n",
    "    Plot ROC AUC vs number of features for each scaler\n",
    "    scaler_results_dict: dictionary with scaler names as keys and their feature_test_results as values\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    scaler_names = list(scaler_results_dict.keys())\n",
    "\n",
    "    for i, (scaler_name, results) in enumerate(scaler_results_dict.items()):\n",
    "        ax = axes[i]\n",
    "\n",
    "        # Extract data for plotting\n",
    "        n_features = list(results.keys())\n",
    "        roc_scores = list(results.values())\n",
    "\n",
    "        # Create the plot\n",
    "        ax.plot(n_features, roc_scores, 'b-o', linewidth=2, markersize=4)\n",
    "        ax.set_title(f'{scaler_name}', fontsize=14, fontweight='bold')\n",
    "        ax.set_xlabel('Number of features selected', fontsize=12)\n",
    "        ax.set_ylabel('ROC AUC', fontsize=12)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # Find and highlight best point\n",
    "        best_idx = roc_scores.index(max(roc_scores))\n",
    "        ax.plot(n_features[best_idx], roc_scores[best_idx], 'ro', markersize=8,\n",
    "                label=f'Best: {max(roc_scores):.4f}')\n",
    "        ax.legend()\n",
    "\n",
    "        # Set consistent y-axis limits for comparison\n",
    "        ax.set_ylim([min(min(results.values()) for results in scaler_results_dict.values()) - 0.001,\n",
    "                     max(max(results.values()) for results in scaler_results_dict.values()) + 0.001])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('ROC AUC vs Number of Features by Scaler', fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.show()\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T18:02:20.328924Z",
     "start_time": "2025-06-05T18:02:20.309681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "@dataclass\n",
    "class FeatureSelectionResult:\n",
    "    \"\"\"Data class to hold feature selection results\"\"\"\n",
    "    best_scaler_name: str\n",
    "    best_scaler: Any\n",
    "    feature_indices: np.ndarray\n",
    "    final_model: RandomForestClassifier\n",
    "    feature_names: np.ndarray\n",
    "    val_roc_auc: float\n",
    "    best_n_features: int\n",
    "    best_params: Dict\n",
    "    test_predictions: np.ndarray\n",
    "\n",
    "class OptimizedFeatureSelector:\n",
    "    \"\"\"\n",
    "    High-performance feature selection pipeline optimized for ROC AUC using RFECV\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cv_folds: int = 5, n_jobs: int = -1, random_state: int = 42,\n",
    "                 rfecv_step: float = 5, rfecv_min_features: int = 5):\n",
    "        self.cv_folds = cv_folds\n",
    "        self.n_jobs = n_jobs\n",
    "        self.random_state = random_state\n",
    "        self.rfecv_step = rfecv_step \n",
    "        self.rfecv_min_features = rfecv_min_features  # Minimum number of features to select\n",
    "        self.estimator = RandomForestClassifier(\n",
    "            n_estimators=600,\n",
    "            random_state=self.random_state,\n",
    "            n_jobs=-1,\n",
    "        )\n",
    "        # Optimized hyperparameter grid for ROC AUC\n",
    "        self.rf_param_grid = {\n",
    "            # More trees generally improve ROC AUC stability\n",
    "            'n_estimators': [300, 500, 800],\n",
    "            # Keep depth options but add more granular control\n",
    "            'max_depth': [8, 12, 16, None],\n",
    "            # Feature sampling - crucial for ROC AUC\n",
    "            'max_features': ['sqrt', 'log2', 0.3, 0.5],\n",
    "            # Lower splits can help with ROC AUC by creating more nuanced decision boundaries\n",
    "            'min_samples_split': [2, 5, 10, 15],\n",
    "            # Leaf size affects probability calibration\n",
    "            'min_samples_leaf': [1, 2, 4, 8],\n",
    "            # Bootstrap sampling ratio - very important for ROC AUC\n",
    "            'max_samples': [0.7, 0.8, 0.9, None],\n",
    "            # Essential for imbalanced datasets and ROC AUC\n",
    "            'class_weight': ['balanced', 'balanced_subsample', None],\n",
    "            # Both criteria can work well for ROC AUC\n",
    "            'criterion': ['gini', 'entropy'],\n",
    "            # Bootstrap vs extra trees - affects ensemble diversity\n",
    "            'bootstrap': [True, False]\n",
    "        }\n",
    "        # Scalers to test\n",
    "        self.scalers = {\n",
    "            'RobustScaler': RobustScaler(),\n",
    "            'MinMaxScaler': MinMaxScaler(),\n",
    "            # 'StandardScaler': StandardScaler(),\n",
    "            # 'No Scaling': None  # No scaling option\n",
    "        }\n",
    "\n",
    "    def _validate_inputs(self, X_train, y_train, X_val, y_val, X_test, feature_names):\n",
    "        \"\"\"Validate and convert inputs to consistent format\"\"\"\n",
    "        # Convert to numpy arrays\n",
    "        X_train = self._to_numpy(X_train)\n",
    "        X_val = self._to_numpy(X_val)\n",
    "        X_test = self._to_numpy(X_test)\n",
    "        y_train = self._to_numpy(y_train).ravel()\n",
    "        y_val = self._to_numpy(y_val).ravel()\n",
    "\n",
    "        # Validate feature names\n",
    "        feature_names = self._validate_feature_names(feature_names, X_train.shape[1])\n",
    "\n",
    "        # Basic validation\n",
    "        assert X_train.shape[1] == X_val.shape[1] == X_test.shape[1], \"Feature dimension mismatch\"\n",
    "        assert len(feature_names) == X_train.shape[1], \"Feature names length mismatch\"\n",
    "\n",
    "        return X_train, y_train, X_val, y_val, X_test, feature_names\n",
    "\n",
    "    def _to_numpy(self, data):\n",
    "        \"\"\"Convert data to numpy array\"\"\"\n",
    "        if hasattr(data, 'values'):\n",
    "            return data.values\n",
    "        return np.array(data) if not isinstance(data, np.ndarray) else data\n",
    "\n",
    "    def _validate_feature_names(self, feature_names, n_features):\n",
    "        \"\"\"Validate and convert feature names\"\"\"\n",
    "        if feature_names is None:\n",
    "            return np.array([f'feature_{i}' for i in range(n_features)])\n",
    "\n",
    "        if hasattr(feature_names, 'values'):\n",
    "            return feature_names.values\n",
    "        elif hasattr(feature_names, '__iter__') and not isinstance(feature_names, str):\n",
    "            return np.array(list(feature_names))\n",
    "        else:\n",
    "            return np.array(feature_names)\n",
    "\n",
    "    def _apply_scaling(self, scaler, X_train, X_val, X_test):\n",
    "        \"\"\"Apply scaling transformation\"\"\"\n",
    "        if scaler is None:\n",
    "            return X_train.copy(), X_val.copy(), X_test.copy()\n",
    "\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_val_scaled = scaler.transform(X_val)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        return X_train_scaled, X_val_scaled, X_test_scaled\n",
    "\n",
    "    def _perform_rfecv(self, X_train, y_train):\n",
    "        \"\"\"Perform RFECV feature selection\"\"\"\n",
    "        # RFECV with ROC AUC scoring\\\n",
    "\n",
    "        model = RFECV(\n",
    "            estimator=self.estimator,\n",
    "            step=self.rfecv_step,\n",
    "            min_features_to_select=self.rfecv_min_features,\n",
    "            cv=StratifiedKFold(n_splits=self.cv_folds, shuffle=True, random_state=self.random_state),\n",
    "            scoring='roc_auc',\n",
    "            n_jobs=self.n_jobs,\n",
    "            verbose=1,\n",
    "        )\n",
    "        logger.info(\"Starting RFECV feature selection...\")\n",
    "        model.fit(X_train, y_train)\n",
    "        logger.info(f\"RFECV selected {model.n_features_} features out of {X_train.shape[1]}\")\n",
    "        return model\n",
    "\n",
    "    def _optimize_hyperparameters(self, X_train, y_train):\n",
    "        \"\"\"Optimize hyperparameters using GridSearchCV\"\"\"\n",
    "        grid_search = HalvingGridSearchCV(\n",
    "            estimator=self.estimator,\n",
    "            param_grid=self.rf_param_grid,\n",
    "            scoring='roc_auc',\n",
    "            n_jobs=self.n_jobs,\n",
    "            cv=self.cv_folds,\n",
    "            return_train_score=False,\n",
    "            random_state=self.random_state,\n",
    "            verbose=1\n",
    "        )\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        return grid_search\n",
    "    \n",
    "    def _create_feature_importance_df(self, rfecv, feature_names, selected_features_mask, selected_feature_indices, scaler_name):\n",
    "        \n",
    "        # Create feature importance DataFrame for visualization\n",
    "        if hasattr(rfecv.estimator_, 'feature_importances_'):\n",
    "            # Get feature importance from the final RFECV estimator\n",
    "            all_importances = np.zeros(len(feature_names))\n",
    "            all_importances[selected_feature_indices] = rfecv.estimator_.feature_importances_\n",
    "\n",
    "            feature_imp_df = pd.DataFrame({\n",
    "                'Feature': feature_names,\n",
    "                'Selected': selected_features_mask,\n",
    "                'Importance': all_importances,\n",
    "                'Ranking': rfecv.ranking_\n",
    "            }).sort_values('Importance', ascending=False)\n",
    "            feature_imp_df.to_csv(f'rfecv_results_{scaler_name.lower()}.csv', index=False)\n",
    "            logger.info(f\"Feature importances saved to rfecv_results_{scaler_name.lower()}.csv\")\n",
    "            \n",
    "    def _evaluate_scaler(self, scaler_name, scaler, X_train, X_val, X_test, y_train, y_val, feature_names):\n",
    "        \"\"\"Evaluate a single scaler configuration with RFECV\"\"\"\n",
    "        logger.info(f\"Testing {scaler_name}...\")\n",
    "\n",
    "        # Apply scaling\n",
    "        X_train_scaled, X_val_scaled, X_test_scaled = self._apply_scaling(\n",
    "            scaler, X_train, X_val, X_test\n",
    "        )\n",
    "\n",
    "        # Perform RFECV feature selection\n",
    "        rfecv = self._perform_rfecv(X_train_scaled, y_train)\n",
    "\n",
    "        # Get selected features\n",
    "        selected_features_mask = rfecv.support_\n",
    "        selected_feature_indices = np.where(selected_features_mask)[0]\n",
    "\n",
    "        self._create_feature_importance_df(rfecv, feature_names, selected_features_mask, selected_feature_indices, scaler_name)\n",
    "        \n",
    "        # Select features for hyperparameter optimization\n",
    "        X_train_selected = X_train_scaled[:, selected_feature_indices]\n",
    "        X_val_selected = X_val_scaled[:, selected_feature_indices]\n",
    "\n",
    "        # Optimize hyperparameters on selected features\n",
    "        logger.info(\"Optimizing hyperparameters on selected features...\")\n",
    "        grid_search = self._optimize_hyperparameters(X_train_selected, y_train)\n",
    "\n",
    "        # Evaluate on validation set\n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_val_pred_proba = best_model.predict_proba(X_val_selected)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_val_pred_proba)\n",
    "\n",
    "        logger.info(f\"{scaler_name} - Validation ROC AUC: {roc_auc:.4f}\")\n",
    "        logger.info(f\"{scaler_name} - CV ROC AUC: {grid_search.best_score_:.4f}\")\n",
    "        return {\n",
    "            'scaler_name': scaler_name,\n",
    "            'scaler': scaler,\n",
    "            'rfecv': rfecv,\n",
    "            'selected_feature_indices': selected_feature_indices,\n",
    "            'n_features': len(selected_feature_indices),\n",
    "            'val_roc_auc': roc_auc,\n",
    "            'cv_roc_auc': grid_search.best_score_,\n",
    "            'best_params': grid_search.best_params_,\n",
    "            'best_model': best_model,\n",
    "            'scaled_data': (X_train_scaled, X_val_scaled, X_test_scaled),\n",
    "        }\n",
    "\n",
    "    def fit(self, X_train, y_train, X_val, y_val, X_test) -> FeatureSelectionResult:\n",
    "        \"\"\"\n",
    "        Main method to perform optimized feature selection with RFECV\n",
    "        \n",
    "        Args:\n",
    "            X_train, y_train: Training data\n",
    "            X_val, y_val: Validation data\n",
    "            X_test: Test data\n",
    "            feature_names: Feature names (optional)\n",
    "            \n",
    "        Returns:\n",
    "            FeatureSelectionResult with optimized model and features\n",
    "        \"\"\"\n",
    "        logger.info(\"Starting optimized feature selection pipeline with RFECV...\")\n",
    "        feature_names = X_train.columns\n",
    "        # Validate inputs\n",
    "        X_train, y_train, X_val, y_val, X_test, feature_names = self._validate_inputs(\n",
    "            X_train, y_train, X_val, y_val, X_test, feature_names\n",
    "        )\n",
    "        best_overall_score = 0\n",
    "        best_config = None\n",
    "\n",
    "        # Test each scaler\n",
    "        for scaler_name, scaler in self.scalers.items():\n",
    "            try:\n",
    "                config = self._evaluate_scaler(\n",
    "                    scaler_name, scaler, X_train, X_val, X_test,\n",
    "                    y_train, y_val, feature_names\n",
    "                )\n",
    "\n",
    "                if config and config['cv_roc_auc'] > best_overall_score:\n",
    "                    best_overall_score = config['cv_roc_auc']\n",
    "                    best_config = config\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Error evaluating {scaler_name}: {str(e)}\")\n",
    "                continue\n",
    "        if best_config is None:\n",
    "            raise ValueError(\"No successful configuration found!\")\n",
    "        logger.info(f\"Best overall: {best_config['scaler_name']} with CV ROC AUC {best_overall_score:.4f}\")\n",
    "        logger.info(f\"Selected {best_config['n_features']} features\")\n",
    "        \n",
    "        return self._create_final_result(best_config, feature_names)\n",
    "\n",
    "    def _create_final_result(self, best_config, feature_names) -> FeatureSelectionResult:\n",
    "        \"\"\"Create the final FeatureSelectionResult\"\"\"\n",
    "        # Get selected feature information\n",
    "        feature_indices = best_config['selected_feature_indices']\n",
    "        final_feature_names = feature_names[feature_indices]\n",
    "\n",
    "        # Get scaled test data and make final predictions\n",
    "        X_test_scaled = best_config['scaled_data'][2]\n",
    "        X_test_final = X_test_scaled[:, feature_indices]\n",
    "        test_predictions = best_config['best_model'].predict_proba(X_test_final)[:, 1]\n",
    "\n",
    "        logger.info(f\"Final model Validation ROC AUC: {best_config['val_roc_auc']:.4f}\")\n",
    "        logger.info(f\"Final model CV ROC AUC: {best_config['cv_roc_auc']:.4f}\")\n",
    "        logger.info(f\"Selected features: {final_feature_names[:5]}...\")\n",
    "\n",
    "        return FeatureSelectionResult(\n",
    "            best_scaler_name=best_config['scaler_name'],\n",
    "            best_scaler=best_config['scaler'],\n",
    "            feature_indices=feature_indices,\n",
    "            final_model=best_config['best_model'],\n",
    "            feature_names=final_feature_names,\n",
    "            val_roc_auc=best_config['val_roc_auc'],\n",
    "            best_n_features=best_config['n_features'],\n",
    "            best_params=best_config['best_params'],\n",
    "            test_predictions=test_predictions,\n",
    "        )\n",
    "\n",
    "# Usage function\n",
    "def optimized_feature_selection(X_train, y_train, X_val, y_val, X_test,\n",
    ") -> FeatureSelectionResult:\n",
    "    \"\"\"\n",
    "    Optimized feature selection pipeline using RFECV for maximum ROC AUC\n",
    "    \n",
    "    Args:\n",
    "        X_train, y_train: Training data and labels\n",
    "        X_val, y_val: Validation data and labels  \n",
    "        X_test: Test data\n",
    "    Returns:\n",
    "        FeatureSelectionResult with optimized model and selected features\n",
    "    \"\"\"\n",
    "    selector = OptimizedFeatureSelector()\n",
    "    return selector.fit(X_train, y_train, X_val, y_val, X_test)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "results: FeatureSelectionResult = optimized_feature_selection(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    X_test,\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X4y2MZ-IUPBe",
    "outputId": "7312cd53-00d8-4e9a-c3d3-c2016bae4cd4",
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-06-05T18:02:20.329428Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 14:02:20,331 - INFO - Starting optimized feature selection pipeline with RFECV...\n",
      "2025-06-05 14:02:20,405 - INFO - Testing RobustScaler...\n",
      "2025-06-05 14:02:20,598 - INFO - Starting RFECV feature selection...\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "print(results)\n",
    "# \"\"\"Data class to hold feature selection results\"\"\"\n",
    "# best_scaler_name: str\n",
    "# best_scaler: Any\n",
    "# feature_indices: np.ndarray\n",
    "# final_model: RandomForestClassifier\n",
    "# feature_names: np.ndarray\n",
    "# val_roc_auc: float\n",
    "# best_n_features: int\n",
    "# best_params: Dict\n",
    "# test_predictions: np.ndarray"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "submission_array = np.vstack([test_features['ID'].values, results.test_predictions]).T\n",
    "submission_df = pd.DataFrame(submission_array, columns=['ID', 'radiant_win']).reset_index(drop=True)\n",
    "submission_df.to_csv('simple_baseline.csv', index=None)"
   ],
   "metadata": {
    "id": "0ZlqtdYdUALp",
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
